{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/22/2019 13:34:46 - INFO - summarizer.preprocessing.cleaner -   'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='0'  # don't occupy GPU, inference can work on CPU\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from flair.embeddings import BertEmbeddings\n",
    "from flair.data import Sentence\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from python_ev.dataset import load_parts, load_df\n",
    "# from vectorizers.bert_boris.bert_base_spwsi import BertBaseSPWSI\n",
    "# from subtask1_solutions.base_solution import Subtask1BaseVectorizerFactory\n",
    "# import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_list_of_inputs(sent, tok = 'MASK', lemma = ''):\n",
    "    tokens = sent.split(' ')\n",
    "    res = []\n",
    "    for i in range(0, len(tokens) + 1):\n",
    "        tokens = sent.split(' ')\n",
    "        tokens.insert(i, tok)\n",
    "        tokens.insert(i+1, tok) # убрать\n",
    "        res.append({str(i):(tokens, i, lemma)})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=119547, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case = False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Я думаю, она вскоре будет на ногах и через несколько дней на пути к выздоровлению.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Я',\n",
       " 'ду',\n",
       " '##ма',\n",
       " '##ю',\n",
       " ',',\n",
       " 'она',\n",
       " 'вскоре',\n",
       " 'будет',\n",
       " 'на',\n",
       " 'но',\n",
       " '##гах',\n",
       " 'и',\n",
       " 'через',\n",
       " 'несколько',\n",
       " 'дней',\n",
       " 'на',\n",
       " 'пути',\n",
       " 'к',\n",
       " 'вы',\n",
       " '##здо',\n",
       " '##ров',\n",
       " '##лению',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.insert(17, '[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.insert(0, '[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_ids = [0 for x in range(len(indexed_tokens))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=119547, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "segments_tensors = torch.tensor([segments_ids]).to('cuda')\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_index = torch.argmax(predictions[0, 17]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'пути'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_layer(tok_sent, verb_list, tokenizer, index, model, threshold):\n",
    "    # получаем предложение, список глаголов, токенизатор, индекс конца слова; возвращаем \"похожие\" токенизированные слова\n",
    "    # также подаём на вход модель; threshold - количество получаемых элементов\n",
    "    #model.to('cuda')\n",
    "    #tok_sent = tokenizer.tokenize(sent) # пока что\n",
    "    res = {}\n",
    "    if (len(verb_list) == 1):\n",
    "        verb = verb_list[0] # список из k элементов (k - количество токенов)\n",
    "        num_tokens = len(verb)\n",
    "        for i in range(index+2, len(tok_sent)+1):\n",
    "            if (i == len(tok_sent) or tok_sent[i].isalpha() or tok_sent[i].isdigit()):\n",
    "                new_tok = tok_sent.copy()\n",
    "                print(tok_sent[i-1])\n",
    "                print('=====')\n",
    "                # тогда перед этим всем вставляем num_tokens токенов\n",
    "                for _ in range(num_tokens):\n",
    "                    new_tok.insert(i, '[MASK]')\n",
    "                print(f'INPUT_TO_BERT: {new_tok}')\n",
    "                indexed_tokens = torch.tensor([tokenizer.convert_tokens_to_ids(new_tok)]).to('cuda')\n",
    "                segment_ids = torch.tensor([[0 for x in range(indexed_tokens.shape[1])]]).to('cuda')\n",
    "                #print(indexed_tokens)\n",
    "                #print(segment_ids)\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(indexed_tokens, segment_ids)\n",
    "                predictions = predictions.cpu()\n",
    "                res[i] = []\n",
    "                for j in range(i, i+num_tokens):\n",
    "                    #predictions.cpu()[0, j].numpy().argsort(axis = 1).T[-10:][::-1].T\n",
    "                    predicted_indexes = predictions.cpu()[0, j].numpy().argsort()[-threshold:][::-1]\n",
    "                    predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_indexes)\n",
    "                    res[i].append(predicted_tokens)\n",
    "                    print(predicted_tokens)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['М',\n",
       " '##ага',\n",
       " '##зин',\n",
       " '##чик',\n",
       " 'был',\n",
       " 'мал',\n",
       " '##ень',\n",
       " '##ким',\n",
       " ',',\n",
       " 'а',\n",
       " 'м',\n",
       " '##яс',\n",
       " '##ник',\n",
       " 'и',\n",
       " 'его',\n",
       " 'су',\n",
       " '##пруга',\n",
       " 'очень',\n",
       " 'большим',\n",
       " '##и',\n",
       " ',',\n",
       " 'поэтому',\n",
       " ',',\n",
       " 'когда',\n",
       " 'к',\n",
       " 'ним',\n",
       " 'при',\n",
       " '##ба',\n",
       " '##вили',\n",
       " '##сь',\n",
       " 'мы',\n",
       " 'с',\n",
       " 'женой',\n",
       " ',',\n",
       " 'в',\n",
       " 'ла',\n",
       " '##в',\n",
       " '##ке',\n",
       " 'стало',\n",
       " 'сов',\n",
       " '##сем',\n",
       " 'те',\n",
       " '##сно',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = 'Магазинчик был маленьким, а мясник и его супруга очень большими, поэтому, когда к ним прибавились мы с женой, в лавке стало совсем тесно.'\n",
    "tokenizer.tokenize(st)\n",
    "#tokenizer.tokenize('содержат')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottom_layer(st, [[' ' for x in range(1)]], tokenizer, 0, model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['был']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('был')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.convert_ids_to_tokens(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_layer(tok_sent, verb, tokenizer, index, model, threshold, sent):\n",
    "    # принимает на вход предложение, глагол, токенизатор, индекс, модель и threshold+sent; возвращает список форм глагола\n",
    "    # на этом же слое должно происходить объединение результатов (есть ли гэппинг)\n",
    "    # пока что всё делаем для одной формы глагола\n",
    "    is_gapping = 0\n",
    "    V_pos = []\n",
    "    V_pos_res = \"\"\n",
    "    cV_pos = \"-1:-1\"\n",
    "    tok_verb = tokenizer.tokenize(verb)\n",
    "    generated_words = bottom_layer(tok_sent, [tok_verb], tokenizer, index, model, threshold) # словарь\n",
    "    #print(generated_words)\n",
    "    for key in generated_words.keys():\n",
    "        assert len(generated_words[key]) == len(tok_verb)\n",
    "        assert len(generated_words[key]) > 0\n",
    "        gapping_flag = 1\n",
    "        for i in range(len(tok_verb)):\n",
    "            if tok_verb[i] not in generated_words[key][i]:\n",
    "                gapping_flag = 0\n",
    "        if (gapping_flag == 1):\n",
    "            is_gapping = 1\n",
    "            V_pos.append(key)\n",
    "            if (cV_pos == \"-1:-1\"):\n",
    "                tmp = sent.rfind(verb)\n",
    "                cV_pos = f\"{tmp}:{tmp + len(verb)}\"\n",
    "    for elem in V_pos: #TODO: реализовать быстрый поиск позиции слова\n",
    "        tmp = sent.rfind(tok_sent[elem])\n",
    "        V_pos_res += f\"{tmp}:{tmp} \"\n",
    "    return is_gapping, cV_pos, V_pos_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_layer(sent, tokenizer, model, sentence_tokenizer, morph, threshold=10):\n",
    "    # на вход - предложение, токенизатор, модель, threshold, токенизатор для предложений (BasicTokenizer)\n",
    "    search_sent = sent.lower()\n",
    "    tok_sent = tokenizer.tokenize(sent)\n",
    "    tok_verb_sent = sentence_tokenizer.tokenize(search_sent)\n",
    "    print(tok_verb_sent)\n",
    "    verb_list = [word for word in tok_verb_sent if check_verb_in_tags(word, morph) == 'VERB']\n",
    "    print(verb_list)\n",
    "    for verb in verb_list:\n",
    "        verb_pos = search_sent.rfind(verb)\n",
    "        tok_prefix = tokenizer.tokenize(sent[:(verb_pos+len(verb))])\n",
    "        index = len(tok_prefix) + 1\n",
    "        is_gapping, cV_pos, V_pos = middle_layer(tok_sent, verb, tokenizer, index, model, threshold, sent)\n",
    "        if (is_gapping == 1):\n",
    "            return is_gapping, cV_pos, V_pos\n",
    "    return 0, \"-1:-1\", \"-1:-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_layer(tok_sent, verb_list, tokenizer, index, model, threshold):\n",
    "    # получаем предложение, список глаголов, токенизатор, индекс конца слова;возвращаем \"похожие\" токенизированные слова\n",
    "    # также подаём на вход модель; threshold - количество получаемых элементов\n",
    "    #tok_sent = tokenizer.tokenize(sent) # пока что\n",
    "    res = {}\n",
    "    if (len(verb_list) == 1):\n",
    "        verb = verb_list[0]  # список из k элементов (k - количество токенов)\n",
    "        num_tokens = len(verb)\n",
    "        print(f\"{verb} --\\n {index} --\\n {tok_sent}\")\n",
    "        for i in range(index+2, len(tok_sent)):\n",
    "            if (tok_sent[i].isalpha() or tok_sent[i].isdigit()):\n",
    "                # TODO: добавить предыдущее слово\n",
    "                    new_tok = tok_sent.copy()\n",
    "                    # тогда перед этим всем вставляем num_tokens токенов\n",
    "                    for _ in range(num_tokens):\n",
    "                        new_tok.insert(i, '[MASK]')\n",
    "                    indexed_tokens = torch.tensor([tokenizer.convert_tokens_to_ids(new_tok)]).to('cuda')\n",
    "                    segment_ids = torch.tensor([[0 for x in range(indexed_tokens.shape[1])]]).to('cuda')\n",
    "                    #print(indexed_tokens)\n",
    "                    #print(segment_ids)\n",
    "                    with torch.no_grad():\n",
    "                        predictions = model(indexed_tokens, segment_ids)\n",
    "                    predictions = predictions.cpu()\n",
    "                    res[i] = []\n",
    "                    for j in range(i, i+num_tokens):\n",
    "                        #predictions.cpu()[0, j].numpy().argsort(axis = 1).T[-10:][::-1].T\n",
    "                        predicted_indexes = predictions[0, j].numpy().argsort()[-threshold:][::-1]\n",
    "                        predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_indexes)\n",
    "                        res[i].append(predicted_tokens)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BasicTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra import check_verb_in_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = BasicTokenizer(do_lower_case=False)\n",
    "st = 'Мастер выполняет необрезной маникюр, для придания формы используются особые щадящие мелкозернистые пилочки, а для дезинфекции эффективные антисептики.'\n",
    "wtmp = tmp.tokenize(st)\n",
    "tst = tokenizer.tokenize(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['мастер', 'выполняет', 'необрезной', 'маникюр', ',', 'для', 'придания', 'формы', 'используются', 'особые', 'щадящие', 'мелкозернистые', 'пилочки', ',', 'а', 'для', 'дезинфекции', 'эффективные', 'антисептики', '.']\n",
      "['выполняет', 'используются']\n",
      "['вы', '##по', '##л', '##няет'] --\n",
      " 8 --\n",
      " ['М', '##аст', '##ер', 'вы', '##по', '##л', '##няет', 'не', '##об', '##рез', '##ной', 'ма', '##ник', '##ю', '##р', ',', 'для', 'при', '##дания', 'формы', 'используются', 'ос', '##обы', '##е', 'щ', '##ад', '##ящие', 'м', '##ел', '##ко', '##зер', '##нис', '##тые', 'п', '##ило', '##чки', ',', 'а', 'для', 'де', '##зин', '##фе', '##кции', 'э', '##ффект', '##ивные', 'ан', '##ти', '##се', '##п', '##тики', '.']\n",
      "['используются'] --\n",
      " 22 --\n",
      " ['М', '##аст', '##ер', 'вы', '##по', '##л', '##няет', 'не', '##об', '##рез', '##ной', 'ма', '##ник', '##ю', '##р', ',', 'для', 'при', '##дания', 'формы', 'используются', 'ос', '##обы', '##е', 'щ', '##ад', '##ящие', 'м', '##ел', '##ко', '##зер', '##нис', '##тые', 'п', '##ило', '##чки', ',', 'а', 'для', 'де', '##зин', '##фе', '##кции', 'э', '##ффект', '##ивные', 'ан', '##ти', '##се', '##п', '##тики', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, '56:68', '110:110 126:126 ')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_layer(st, tokenizer, model, tmp, morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BasicTokenizer.tokenize of <pytorch_pretrained_bert.tokenization.BasicTokenizer object at 0x7f6707dc3550>>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NOUN'}"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x.tag.POS for x in morph.parse('овгз'.lower()) if x.score > 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['например',\n",
       " ',',\n",
       " 'с',\n",
       " 'помощью',\n",
       " 'штатива',\n",
       " 'можно',\n",
       " 'выполнять',\n",
       " 'съемку',\n",
       " 'с',\n",
       " 'автоматическим',\n",
       " 'началом',\n",
       " 'записи',\n",
       " 'или',\n",
       " 'снимать',\n",
       " 'объекты',\n",
       " 'при',\n",
       " 'недостаточном',\n",
       " 'освещении',\n",
       " ',',\n",
       " 'например',\n",
       " 'феиерверки',\n",
       " 'и',\n",
       " 'ночные',\n",
       " 'виды',\n",
       " '.']"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.tokenize(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##ые\n",
      "=====\n",
      "INPUT_TO_BERT: ['по', 'результатам', 'со', '##рев', '##нова', '##нии', 'че', '##тве', '##ро', 'спорт', '##с', '##менов', 'под', '##тве', '##рди', '##ли', 'з', '##елен', '##ые', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'по', '##яса', ',', 'шест', '##еро', '-', 'же', '##лт', '##ые', '.']\n",
      ",\n",
      "=====\n",
      "INPUT_TO_BERT: ['по', 'результатам', 'со', '##рев', '##нова', '##нии', 'че', '##тве', '##ро', 'спорт', '##с', '##менов', 'под', '##тве', '##рди', '##ли', 'з', '##елен', '##ые', 'по', '##яса', ',', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'шест', '##еро', '-', 'же', '##лт', '##ые', '.']\n",
      "-\n",
      "=====\n",
      "INPUT_TO_BERT: ['по', 'результатам', 'со', '##рев', '##нова', '##нии', 'че', '##тве', '##ро', 'спорт', '##с', '##менов', 'под', '##тве', '##рди', '##ли', 'з', '##елен', '##ые', 'по', '##яса', ',', 'шест', '##еро', '-', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'же', '##лт', '##ые', '.']\n",
      ".\n",
      "=====\n",
      "INPUT_TO_BERT: ['по', 'результатам', 'со', '##рев', '##нова', '##нии', 'че', '##тве', '##ро', 'спорт', '##с', '##менов', 'под', '##тве', '##рди', '##ли', 'з', '##елен', '##ые', 'по', '##яса', ',', 'шест', '##еро', '-', 'же', '##лт', '##ые', '.', '[MASK]', '[MASK]', '[MASK]', '[MASK]']\n",
      "{19: [['цвета', 'цвет', 'кол', 'че', 'с', 'и', 'з', 'т', 'в', 'бо', 'р', 'к', 'п', 'стр', 'ф', 'ч', 'о', 'ко', 'се', 'же'], ['##рас', '##ёл', 'се', '##ы', 'ч', '##оло', 'з', 'бел', '##ры', '##ел', 'с', 'ж', '##ёр', '##и', 'на', 'в', 'че', 'бо', '##ре', '##ни'], ['##ёл', '##рас', 'син', 'цвет', 'бел', '##ёр', '##ры', '##ы', '##же', '-', 'золото', 'се', '##оло', '##ов', '##пур', '##ичне', '##вет', 'и', '##ел', '##пий'], ['##ые', '##го', '##ого', '##ного', '##вого', '##ёрного', '##ового', 'цвета', '##ные', '##ского', '##овые', 'из', '##чного', 'цвет', '##того', '##рного', '##кового', '##очного', '-', '##тые']], 22: [['в', 'а', 'на', 'че', 'по', 'т', 'с', 'во', 'за', 'ч', 'и', 'дев', 'два', 'п', 'три', 'шест', 'д', 'у', 'две', 'но'], ['-', 'в', 'т', 'че', 'на', '##тве', 'и', 'с', 'из', 'по', 'се', 'во', 'шест', 'ч', 'за', 'два', 'не', 'четыре', 'три', 'дев'], ['-', '##е', 'из', ',', 'в', 'и', '##рое', '##х', '##тве', 'по', 'четыре', '##надцать', '##о', 'три', 'же', 'два', '##ретье', 'с', 'пять', '##еры'], ['и', ',', '-', '##е', '##х', 'них', '##шиеся', 'из', 'этапе', '##шие', 'же', '##но', 'с', 'года', 'которых', 'по', '##и', '##финале', 'ещё', 'числе']], 25: [['ж', 'се', 'же', 'ч', 'з', 'син', 'с', 'че', 'кор', 'к', 'б', 'бел', 'м', 'р', 'ол', 'п', 'бу', 'т', 'гол', 'в'], ['##ёл', '##ичне', '##рас', '##оло', '##елен', '##ел', '##ём', '##ёр', 'син', '##лт', '##ле', 'се', '##он', 'бел', '##рв', '##ры', 'ж', '##ов', '##елы', 'свет'], ['##ые', '##е', '##тые', '##ные', '##вые', '##ёные', '##о', '##но', ',', '##овые', 'и', '##ние', '##кие', '##вое', '-', 'цвета', '##ы', '##лые', '##то', '##ие'], ['-', 'и', ',', 'или', '/', '##е', '##ые', '##ные', 'либо', '##но', 'более', '##о', 'на', 'были', '##ы', '##тые', 'не', 'с', '##и', 'также']], 29: [['В', 'По', 'На', 'С', 'После', 'О', 'И', 'Со', 'За', 'П', 'К', 'У', 'М', 'Про', 'Участник', 'При', 'От', 'Ф', 'Ч', 'Т'], ['-', 'итогам', '##бед', '##с', '##ревнования', 'в', '##рев', 'по', 'результат', '##им', 'с', '##м', 'и', 'финал', '##и', 'на', '##о', ',', 'из', '##тве'], ['-', 'в', 'по', 'года', 'на', ',', 'году', 'соревнований', 'с', 'спорт', '##нова', 'и', '##м', '##ревнования', 'из', '##с', 'за', '##е', ':', 'результат'], ['года', 'в', '-', 'по', 'на', ',', '##нова', '.', 'и', 'с', ':', 'за', 'у', '##а', '##ов', '##ревнования', 'вы', 'соревнований', 'из', 'спорт']]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, '-1:-1', '')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_layer(tst, 'подтвердили', tokenizer, 17, model, 20, st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltmp = [word for word in wtmp if check_verb_in_tags(word, morph) == 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "50\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "st = st.replace('й', 'и').replace('ё', 'е')\n",
    "for elem in ltmp:\n",
    "    print(st.rfind(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = tokenizer.tokenize(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['видел', 'был', 'боли']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Он как будто видел\n",
      "Он как будто видел что-то в глубине, и взгляд его был\n",
      "Он как будто видел что-то в глубине, и взгляд его был рассеянным, а выражение лица — полным боли\n"
     ]
    }
   ],
   "source": [
    "for elem in ltmp:\n",
    "    print(st[:(st.rfind(elem) + len(elem))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##л\n",
      "=====\n",
      "-\n",
      "=====\n",
      "то\n",
      "=====\n",
      "в\n",
      "=====\n",
      ",\n",
      "=====\n",
      "и\n",
      "=====\n",
      "##гляд\n",
      "=====\n",
      "его\n",
      "=====\n",
      "был\n",
      "=====\n",
      ",\n",
      "=====\n",
      "а\n",
      "=====\n",
      "##ражение\n",
      "=====\n",
      "[UNK]\n",
      "=====\n",
      "##ным\n",
      "=====\n",
      ".\n",
      "=====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, (50, 53), '85:85 ')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_layer(tst, 'был', tokenizer, 4, model, 10, st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
